{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesar la imagen #\n",
    "\n",
    "El primer paso es procesar la imagen para obtener los coeficientes. Los pasos a seguir son los siguientes:\n",
    "- Recortar la imagen para que sus dimensiones sean múltiplos de 8.\n",
    "- Para cada bloque de 8x8 de una imagen:\n",
    "    - Calcular la transformada discreta del coseno (coeficientes de la DCT).\n",
    "    - Realizar una cuantificación de la transformada: los coeficientes de la DCT cuantificados deben seguir la ley de Benford. La cuantificación surge de redondear al entero más cercano el resultado de dividir un bloque entre una matriz de cuantificación. https://cs.stanford.edu/people/eroberts/courses/soco/projects/data-compression/lossy/jpeg/coeff.htm\n",
    "- Obtener la lista de coeficientes resultante de iterar la matriz de coeficientes en modo zig-zag: el zig-zag recorre primero los coeficientes más importantes (baja frecuencia) y deja los menos relevantes al final (alta frecuencia). Al haber realizado la cuantificación, los primeros valores de la lista serán enteros distintos de 0 y los últimos serán, en su mayoría, 0.\n",
    "\n",
    "Ejemplo modo zig-zag:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 5 & 6\\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}\n",
    "\\rightarrow [1, 2, 4, 7, 5, 3, 6, 8, 9]\n",
    "\\end{equation*}\n",
    "\n",
    "El siguiente código proporciona métodos para recortar la imagen, para hallar la DCT de un bloque, realizar la cuantificación de la transformada de un bloque y calcular una lista de coeficientes en modo zig-zag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch configuration\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "BLOCK_SIZE = 8\n",
    "\n",
    "EPSILON = 1e-6\n",
    "\n",
    "BASE_QUANTIZATION_MATRIX = torch.tensor([\n",
    "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "    ], dtype=torch.float, device=device)\n",
    "\n",
    "ZIGZAG_INDICES = torch.tensor([\n",
    "        [0, 1, 5, 6, 14, 15, 27, 28],\n",
    "        [2, 4, 7, 13, 16, 26, 29, 42],\n",
    "        [3, 8, 12, 17, 25, 30, 41, 43],\n",
    "        [9, 11, 18, 24, 31, 40, 44, 53],\n",
    "        [10, 19, 23, 32, 39, 45, 52, 54],\n",
    "        [20, 22, 33, 38, 46, 51, 55, 60],\n",
    "        [21, 34, 37, 47, 50, 56, 59, 61],\n",
    "        [35, 36, 48, 49, 57, 58, 62, 63]\n",
    "    ], dtype=torch.long, device=device).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, block_size):\n",
    "    \"\"\"\n",
    "    Crop image to a size that is a multiple of block_size\n",
    "\n",
    "    Parameters:\n",
    "    - image (torch.Tensor): input image\n",
    "    - block_size (int): block size\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: cropped image\n",
    "    \"\"\"\n",
    "    \n",
    "    h, w = image.shape[-2:]\n",
    "    h_new = h - h % block_size\n",
    "    w_new = w - w % block_size\n",
    "    return image[..., :h_new, :w_new]\n",
    "\n",
    "# https://github.com/zh217/torch-dct/blob/master/torch_dct/_dct.py\n",
    "def dct_fft_impl(v):\n",
    "    return torch.view_as_real(torch.fft.fft(v, dim=1))\n",
    "\n",
    "def dct(x):\n",
    "    \"\"\"\n",
    "    Compute 1D Discrete Cosine Transform (DCT-II) using FFT.\n",
    "    \"\"\"\n",
    "    x_shape = x.shape\n",
    "    N = x_shape[-1]\n",
    "    x = x.contiguous().view(-1, N)\n",
    "\n",
    "    v = torch.cat([x[:, ::2], x[:, 1::2].flip([1])], dim=1)\n",
    "\n",
    "    Vc = dct_fft_impl(v)\n",
    "\n",
    "    k = - torch.arange(N, dtype=x.dtype, device=x.device)[None, :] * np.pi / (2 * N)\n",
    "    W_r = torch.cos(k)\n",
    "    W_i = torch.sin(k)\n",
    "\n",
    "    V = Vc[:, :, 0] * W_r - Vc[:, :, 1] * W_i\n",
    "    V[:, 0] /= np.sqrt(N) * 2 # norm='ortho'\n",
    "    V[:, 1:] /= np.sqrt(N / 2) * 2 # norm='ortho'\n",
    "\n",
    "    V = 2 * V.view(*x_shape)\n",
    "\n",
    "    return V\n",
    "\n",
    "def compute_dct(block):\n",
    "    \"\"\"\n",
    "    Compute DCT of an 8x8 block\n",
    "\n",
    "    Parameters:\n",
    "    - block (torch.Tensor): input 8x8 block\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: DCT coefficients\n",
    "    \"\"\"\n",
    "    X1 = dct(block)\n",
    "    X2 = dct(X1.transpose(-1, -2))\n",
    "    return X2.transpose(-1, -2)\n",
    "    \n",
    "\n",
    "def get_quantization_matrix(quality):\n",
    "    \"\"\"\n",
    "    Get quantization matrix for a given quality level\n",
    "\n",
    "    Parameters:\n",
    "    - quality (int): quality level\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: quantization matrix\n",
    "    \"\"\"\n",
    "\n",
    "    if quality < 50:\n",
    "        scale = 5000 / quality\n",
    "    else:\n",
    "        scale = 200 - 2 * quality\n",
    "\n",
    "    quantization_matrix = ((BASE_QUANTIZATION_MATRIX * scale + 50) / 100).int()\n",
    "\n",
    "    quantization_matrix = torch.clamp(quantization_matrix, min=1, max=255)\n",
    "\n",
    "    return quantization_matrix\n",
    "\n",
    "def quantize(block, quant_matrix):\n",
    "    \"\"\"\n",
    "    Quantize an 8x8 block\n",
    "\n",
    "    Parameters:\n",
    "    - block (numpy.ndarray): input 8x8 block\n",
    "    - quant_matrix (torch.Tensor): quantization matrix\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: quantized block\n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.round(block / quant_matrix)\n",
    "\n",
    "def zigzag_order(block):\n",
    "    \"\"\"\n",
    "    Traverse a 2D array in zigzag order\n",
    "\n",
    "    Parameters:\n",
    "    - block (torch.Tensor): input 2D array\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: flattened elements in zigzag order\n",
    "    \"\"\"\n",
    "\n",
    "    return block.flatten()[ZIGZAG_INDICES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Test code\n",
    "########################\n",
    "\n",
    "path = \"dummy-images/natural/natural-1.jpg\"\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image = torch.tensor(image, dtype=torch.float, device=device)\n",
    "\n",
    "image = crop_image(image, BLOCK_SIZE)\n",
    "\n",
    "block = image[:8, :8]\n",
    "\n",
    "Q_50 = get_quantization_matrix(50)\n",
    "print(\"------- Q_50 -------\")\n",
    "print(Q_50)\n",
    "print()\n",
    "\n",
    "print(\"------- Block -------\")\n",
    "print(block)\n",
    "print()\n",
    "\n",
    "# Compute DCT of the block\n",
    "dct_block = compute_dct(block)\n",
    "print(\"------- DCT Block -------\")\n",
    "print(dct_block)\n",
    "print()\n",
    "\n",
    "# Quantize the block\n",
    "quant_block = quantize(dct_block, Q_50)\n",
    "print(\"------- Quantized Block -------\")\n",
    "print(quant_block)\n",
    "print()\n",
    "\n",
    "# Flatten the block in zigzag order\n",
    "print(\"------- Zigzag Block -------\")\n",
    "zigzag_block = zigzag_order(quant_block)\n",
    "print(zigzag_block)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener todos los coeficientes de una imagen #\n",
    "\n",
    "El siguiente paso es hallar todos los coeficientes $c_{n,\\Delta}(k)$. Cada $c_{n,\\Delta}(k)$ representa el coeficiente en la $n$-ésima frecuencia en modo zig-zag obtenida del $k$-ésimo bloque de la imagen y cuantificado con paso $\\Delta$.\n",
    "\n",
    "Para ello, se guardará en una matriz de dimensiones $K \\times Q \\times 64$, donde $K$ es el número de bloques de $8 \\times 8$ en el que se ha dividido la imagen, $Q$ es el número de cuantificaciones realizadas y $64$ indica el número de elementos que tiene una lista al aplicarle zig-zag a un bloque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_coefs(image, quant_matrices):\n",
    "    \"\"\"\n",
    "    Compute DCT coefficients of an image more efficiently.\n",
    "\n",
    "    Parameters:\n",
    "    - image (torch.Tensor): input image\n",
    "    - quant_matrices (list of torch.Tensor): list of quantization matrices\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: DCT coefficients (K, Q, BLOCK_SIZE*BLOCK_SIZE)\n",
    "    \"\"\"\n",
    "\n",
    "    cropped_image = crop_image(image, BLOCK_SIZE)\n",
    "\n",
    "    # Get 8x8 blocks using unfold (better than a loop)\n",
    "    blocks = cropped_image.unfold(0, BLOCK_SIZE, BLOCK_SIZE).unfold(1, BLOCK_SIZE, BLOCK_SIZE)\n",
    "    K = blocks.shape[0] * blocks.shape[1]  # Número total de bloques\n",
    "    Q = len(quant_matrices)  # Número de matrices de cuantización\n",
    "\n",
    "    # Organize everything in a block tensor \n",
    "    blocks = blocks.contiguous().view(K, BLOCK_SIZE, BLOCK_SIZE) # (K, 8, 8)\n",
    "\n",
    "    # Apply DCT\n",
    "    dct_blocks = torch.vmap(compute_dct)(blocks)\n",
    "\n",
    "    # Convert matrices list into a tensor\n",
    "    quant_matrices = torch.stack(quant_matrices)  # (Q, 8, 8)\n",
    "\n",
    "    # Apply quantization to blocks\n",
    "    quantized_blocks = torch.round(dct_blocks.unsqueeze(1) / quant_matrices)  # (K, Q, 8, 8)\n",
    "\n",
    "    # Get frequencies in zig-zag order\n",
    "    coefs = quantized_blocks.flatten(2)[:, :, ZIGZAG_INDICES]\n",
    "\n",
    "    return coefs  # (K, Q, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and convert to grayscale\n",
    "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "image = torch.tensor(image, dtype=torch.float, device=device)\n",
    "\n",
    "# Define quantization matrices for quality factors 50, 80 and 90\n",
    "Q_50 = get_quantization_matrix(50)\n",
    "Q_80 = get_quantization_matrix(80)\n",
    "Q_90 = get_quantization_matrix(90)\n",
    "\n",
    "quant_matrices = [Q_50, Q_80, Q_90]\n",
    "\n",
    "c = get_all_coefs(image, quant_matrices)\n",
    "\n",
    "print(\"------- c_0_0(0) -------\")\n",
    "print(c[0, 0, 0])\n",
    "print()\n",
    "\n",
    "print(\"------- c_0_1(2) -------\")\n",
    "print(c[2, 1, 0]) # Note that the order of the indices is inverted\n",
    "print()\n",
    "\n",
    "print(\"------- coefs -------\")\n",
    "print(c)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer dígito significativo #\n",
    "\n",
    "Realizar el código para la fórmula:\n",
    "\n",
    "$d_{b,n,\\Delta}(k) = \\lfloor \\dfrac{\\mid c_{n,\\Delta}(k) \\mid}{b^{\\lfloor \\text{log}_b \\mid c_{n,\\Delta}(k) \\mid \\rfloor} } \\rfloor$\n",
    "\n",
    "Donde:\n",
    "- $d_{b,n,\\Delta}(k)$ es el primer dígito significante en base b en la n-ésima frecuencia en modo zig-zag obtenida del k-ésimo bloque y cuantificado con paso $\\Delta$.\n",
    "- $c_{n,\\Delta}(k)$ es el coeficiente en la n-ésima frecuencia en modo zig-zag obtenida del k-ésimo bloque y cuantificado con paso $\\Delta$.\n",
    "\n",
    "Una vez se ha obtenido la matriz de coeficientes, se puede calcular la matriz de primeros dígitos añadiéndole la dimensión $B$, siendo ésta el número de bases a utilizar. La matriz resultante será de dimensiones $K \\times Q \\times 64 \\times B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_significant_digit(values, base):\n",
    "    \"\"\"\n",
    "    Computes the first significant digit (FD) of a given values in a specified base.\n",
    "    \n",
    "    Parameters:\n",
    "    - values (torch.Tensor): DCT coefficient values.\n",
    "    - base (int): The numerical base.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: The first significant digit of the input values in the given base.\n",
    "    \"\"\"\n",
    "    values = torch.abs(values)\n",
    "    \n",
    "    fd = torch.zeros_like(values, dtype=torch.uint8, device=device)\n",
    "    \n",
    "    # Select non zero values\n",
    "    mask = values != 0\n",
    "    nonzero_values = values[mask]\n",
    "    \n",
    "    # Apply the formula only to non zero values\n",
    "    exponent = torch.floor(torch.log(nonzero_values) / torch.log(base))\n",
    "    fd_nonzero = torch.floor(nonzero_values / (base ** exponent)).to(torch.uint8)\n",
    "    \n",
    "    fd[mask] = fd_nonzero\n",
    "    \n",
    "    return fd\n",
    "\n",
    "\n",
    "def get_all_digits(coefs, bases):\n",
    "    \"\"\"\n",
    "    Compute the first significant digit of all DCT coefficients in a given base.\n",
    "    \n",
    "    Parameters:\n",
    "    - coefs (torch.Tensor): DCT coefficients.\n",
    "    - bases (list): List of numerical bases.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: First significant digits of all DCT coefficients in the given bases.\n",
    "    \"\"\"\n",
    "    \n",
    "    K, Q, _ = coefs.shape\n",
    "    B = len(bases)\n",
    "    digits = torch.zeros((K, Q, BLOCK_SIZE*BLOCK_SIZE, B), dtype=torch.uint8, device=device)\n",
    "\n",
    "    bases_tensor = torch.as_tensor(bases, dtype=torch.int32, device=device)\n",
    "    for l, base in enumerate(bases_tensor):\n",
    "        digits[...,l] = first_significant_digit(coefs,base)\n",
    "    \n",
    "    return digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_all_digits(c, [10, 20, 40])\n",
    "print(\"------- d_0_0_0(0) -------\")\n",
    "print(d[0, 0, 0, 0])\n",
    "print()\n",
    "\n",
    "print(\"------- d_1_5_1(3) -------\")\n",
    "print(d[3, 1, 5, 1]) # Note that the order of the indices is inverted\n",
    "print()\n",
    "\n",
    "print(\"------- digits -------\")\n",
    "print(d)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF para los primeros dígitos #\n",
    "\n",
    "La función de densidad de probabilidad es la siguiente:\n",
    "\n",
    "$\\hat{p}(d) = \\dfrac{1}{K} \\sum_{k=1}^{K} \\textbf{1}_x(d(k)), d \\in \\{1,2,...,b-1\\}$\n",
    "\n",
    "Donde:\n",
    "\n",
    "\\begin{align*}\n",
    "\\textbf{1}_x(y) = \n",
    "\\left\\{\n",
    "    \\begin {aligned}\n",
    "         & 1 \\quad & x = y \\\\\n",
    "         & 0 \\quad & otherwise                  \n",
    "    \\end{aligned}\n",
    "\\right.\n",
    "\\end{align*}\n",
    "\n",
    "Se utiliza $\\hat{p}(d)$ en lugar de $\\hat{p}_{b,n,\\Delta}(d)$ por temas de compacidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_est(digits, b, n, delta, base):\n",
    "    \"\"\"\n",
    "    Compute the probability density function of the first significant digits of DCT coefficients.\n",
    "    \n",
    "    Parameters:\n",
    "    - digits (torch.Tensor): First significant digits of DCT coefficients.\n",
    "    - b (int): base index.\n",
    "    - n (int): frequency index.\n",
    "    - delta (float): delta index.\n",
    "    - base (int): Numerical base.\n",
    "    \n",
    "    Returns:\n",
    "    - p_est (dict): Probability density function of the first significant digits of DCT coefficients.\n",
    "    \"\"\"\n",
    "    \n",
    "    p_est = {i: 0 for i in range(1, base)}\n",
    "\n",
    "    K = digits.shape[0]\n",
    "\n",
    "    # Get the relevant slice of the tensor 'digits' for the specific (n, delta, b)\n",
    "    relevant_digits = digits[:, delta, n, b]\n",
    "\n",
    "    # Count occurrences of each digit using torch's bincount (efficient counting)\n",
    "    counts = torch.bincount(relevant_digits[relevant_digits > 0], minlength=base)[1:]\n",
    "\n",
    "    # Update p_est with counts\n",
    "    p_est.update({i: counts[i-1].item() for i in range(1, base)})\n",
    "\n",
    "    # Compute total non-zero elements (avoid division by zero)\n",
    "    total = counts.sum().item()\n",
    "    for i in range(1,base):\n",
    "        p_est[i] /= K\n",
    "        if p_est[i] == 0:\n",
    "            p_est[i] = EPSILON\n",
    "    \n",
    "    # Normalize the probabilities\n",
    "    total = sum(p_est.values())\n",
    "    for i in range(1, base):\n",
    "        p_est[i] /= total\n",
    "\n",
    "    return p_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_est = get_pdf_est(d, 0, 5, 2, 10) # b = 0, n = 5, delta = 2, base = 10\n",
    "\n",
    "# Display PDF\n",
    "bars = plt.bar(p_est.keys(), p_est.values())\n",
    "plt.xlabel(\"First Significant Digit\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"PDF of First Significant Digits\")\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimos cuadrados #\n",
    "\n",
    "Para clasificar correctamente las imágenes, hay que comparar la función de densidad de probabilidad obtenida anteriormente con la ecuación generalizada de Benford:\n",
    "\n",
    "$p(d) = \\beta \\text{ log}_{b} (1 + \\dfrac{1}{\\gamma + d^\\delta})$\n",
    "\n",
    "Para estimar los párametros $\\beta, \\gamma$ y $\\delta$ hay que resolver un problema de mínimos cuadrados:\n",
    "\n",
    "$p_{b,n,\\Delta}^{\\text{fit}} = \\underset{p}{\\text{arg min}} \\sum_{d=1}^{b-1} (\\hat{p}_{b,n,\\Delta}(d) - p(d)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benford(d, beta, gamma, delta, base):\n",
    "    \"\"\"Generalized Benford's Law function.\"\"\"\n",
    "    denom = np.clip(gamma + d**delta, EPSILON, None)  # Avoid division by zero\n",
    "    return beta * (np.log(1 + 1 / denom) / np.log(base))\n",
    "\n",
    "def residuals(params, d, p):\n",
    "    \"\"\"Compute residuals for curve fitting.\"\"\"\n",
    "    return benford(d, *params, len(d) + 1) - p\n",
    "\n",
    "def jacobian(params, d, p):\n",
    "    beta, gamma, delta = params\n",
    "    base = len(d) + 1\n",
    "\n",
    "    J_beta = (np.log(1 - 1 / (gamma - d**delta)) / np.log(base))\n",
    "    J_gamma = beta / (np.log(base) * (d**delta - gamma) * (d**delta - gamma + 1))\n",
    "    J_delta = (base * d**delta ** np.log(d)) / (np.log(base) * (d**delta - gamma) * (d**delta - gamma + 1))\n",
    "\n",
    "    return np.vstack((J_beta, J_gamma, J_delta)).T\n",
    "\n",
    "def get_pdf_fit(p_est):\n",
    "    \"\"\"\n",
    "    Fit Benford's Law to the estimated probability density function.\n",
    "    \n",
    "    Parameters:\n",
    "    - p_est (dict): Estimated probability density function (keys: digits, values: probabilities).\n",
    "    \n",
    "    Returns:\n",
    "    - p_fit (dict): Fitted probability density function.\n",
    "    \"\"\"\n",
    "    \n",
    "    p_fit = {}\n",
    "    \n",
    "    d_values = np.array(list(p_est.keys()))\n",
    "    p_values = np.array(list(p_est.values()))\n",
    "\n",
    "    base = len(d_values) + 1\n",
    "\n",
    "    initial_guess = [1, 1, 1]\n",
    "\n",
    "    # popt = opt.least_squares(residuals, initial_guess, jac=jacobian, args=(d_values, p_values))\n",
    "    popt = opt.least_squares(residuals, initial_guess, args=(d_values, p_values))\n",
    "\n",
    "    for i in d_values:\n",
    "        p_fit[i] = benford(i, *popt.x, base)\n",
    "        if p_fit[i] == 0:\n",
    "            p_fit[i] = EPSILON  # Avoid division by zero\n",
    "\n",
    "    # Normalize PDF\n",
    "    p_fit_sum = sum(p_fit.values())\n",
    "    for i in d_values:\n",
    "        p_fit[i] /= p_fit_sum\n",
    "\n",
    "    return p_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fit = get_pdf_fit(p_est)\n",
    "\n",
    "# Display PDF\n",
    "bars = plt.bar(p_fit.keys(), p_fit.values())\n",
    "plt.xlabel(\"First Significant Digit\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Fitted PDF of First Significant Digits\")\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divergencias #\n",
    "\n",
    "Una vez obtenida la distribución $p^{\\text{fit}}$, hay que compararla con $\\hat{p}$. La aptitud se puede medir usando funciones de divergencia, como puede ser la de Jensen-Shanon:\n",
    "\n",
    "$D^{\\text{JS}} (\\hat{p} \\mid p) = D^{\\text{KL}} (\\hat{p} \\mid p) + D^{\\text{KL}} (p \\mid \\hat{p})$,\n",
    "\n",
    "que es una versión simetrizada de la divergencia de Kullback-Leibler:\n",
    "\n",
    "$D^{\\text{KL}} (\\hat{p} \\mid p) = \\sum_{d=1}^{b-1} \\hat{p}(d) \\text{ log}\\dfrac{\\hat{p}(d)}{p(d)} $\n",
    "\n",
    "En ocasiones es preferible utilizar divergencia simetrizada de Renyi, ya que $D^{\\text{JS}}$ puede ser inestable en pdfs sesgadas:\n",
    "\n",
    "$D^{\\text{R}}_{\\alpha} (\\hat{p} \\mid p) = \\dfrac{1}{1-\\alpha} (\\text{log } S_{\\alpha} (\\hat{p}, p) + \\text{log } S_{\\alpha} (p,\\hat{p}))$,\n",
    "\n",
    "también se puede usar la divergencia simetrizada de Tsallis:\n",
    "\n",
    "$D^{\\text{T}}_{\\alpha} (\\hat{p} \\mid p) = \\dfrac{1}{1-\\alpha} (2 - S_{\\alpha} (\\hat{p}, p) - S_{\\alpha} (p,\\hat{p}))$,\n",
    "\n",
    "donde\n",
    "\n",
    "$S_{\\alpha} (q, p) = \\sum_{d=1}^{b-1} \\dfrac{q(d)^\\alpha}{p(d)^{\\alpha - 1}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Compute the Jensen-Shannon divergence between two probability distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - p (dict): First probability distribution.\n",
    "    - q (dict): Second probability distribution.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Jensen-Shannon divergence between p and q.\n",
    "    \"\"\"\n",
    "    \n",
    "    return kl_divergence(p, q) + kl_divergence(q, p)\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Compute the Kullback-Leibler divergence between two probability distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - p (dict): First probability distribution.\n",
    "    - q (dict): Second probability distribution.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Kullback-Leibler divergence between p and q.\n",
    "    \"\"\"\n",
    "    \n",
    "    kl = 0\n",
    "    \n",
    "    for key in p.keys():\n",
    "        kl += p[key] * np.log(p[key] / q[key])\n",
    "    \n",
    "    return kl\n",
    "\n",
    "def r_divergence(p, q, alpha):\n",
    "    \"\"\"\n",
    "    Compute the Renyi divergence between two probability distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - p (dict): First probability distribution.\n",
    "    - q (dict): Second probability distribution.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Renyi divergence between p and q.\n",
    "    \"\"\"\n",
    "    \n",
    "    r = 1 / (1 - alpha) * (np.log(s_function(p, q, alpha)) + np.log(s_function(q, p, alpha)))\n",
    "    \n",
    "    return r\n",
    "\n",
    "def t_divergence(p, q, alpha):\n",
    "    \"\"\"\n",
    "    Compute the Tsallis divergence between two probability distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - p (dict): First probability distribution.\n",
    "    - q (dict): Second probability distribution.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Tsallis divergence between p and q.\n",
    "    \"\"\"\n",
    "    \n",
    "    t = 1 / (1 - alpha) * (2 - s_function(p, q, alpha) - s_function(q, p, alpha))\n",
    "    \n",
    "    return t\n",
    "\n",
    "def s_function(q, p, alpha):\n",
    "    \"\"\"\n",
    "    Compute weighted sum that combines two probability distributions\n",
    "\n",
    "    Parameters:\n",
    "    - q (dict): First probability distribution.\n",
    "    - p (dict): Second probability distribution.\n",
    "    - alpha (float): Weighting factor.\n",
    "\n",
    "    Returns:\n",
    "    - float: Weighted sum of the two probability distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    s = 0\n",
    "\n",
    "    for key in q.keys():\n",
    "        s += (q[key] ** alpha) / (p[key] ** (alpha - 1))\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = js_divergence(p_est, p_fit)\n",
    "r = r_divergence(p_est, p_fit, 0.5)\n",
    "t = t_divergence(p_est, p_fit, 0.5)\n",
    "\n",
    "print(f\"Jensen-Shanon Divergence: {js:.4f}\")\n",
    "print(f\"Renyi Divergence: {r:.4f}\")\n",
    "print(f\"Tsallis Divergence: {t:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector de características #\n",
    "\n",
    "Considerando un conjunto $B$ de bases, un conjunto $N$ de frecuencias y un conjunto $J$ de factores de calidad de JPEG (correspondiente a cada uno de las matrices de cuantificación $\\Delta$), se puede obtener un vector de características concatenando todas las divergencias de la siguiente manera:\n",
    "\n",
    "$\\Phi_{B,N,J} = [D_{b,n,\\Delta}^{\\text{JS}}, D_{b,n,\\Delta}^{\\text{R}}, D_{b,n,\\Delta}^{\\text{T}}]$\n",
    "\n",
    "El vector final tendrá tamaño $|B| \\times |N| \\times |J| \\times 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(image, bases, frequencies, quant_matrices):\n",
    "    \"\"\"\n",
    "    Compute feature vectors of an image\n",
    "    \n",
    "    Parameters:\n",
    "    - image (torch.Tensor): input image\n",
    "    - bases (list): list of numerical bases\n",
    "    - frequencies (list): list of frequency indices\n",
    "    - quant_matrices (list): list of quantization matrices\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: feature vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    coefs = get_all_coefs(image, quant_matrices)\n",
    "    digits = get_all_digits(coefs, bases)\n",
    "    \n",
    "    feature_vectors = torch.zeros((len(bases), len(frequencies), len(quant_matrices), 3), dtype=torch.float32, device=device)\n",
    "\n",
    "    for b, base in enumerate(bases):\n",
    "        for n, frequency in enumerate(frequencies):\n",
    "            for q, _ in enumerate(quant_matrices):\n",
    "                p_est = get_pdf_est(digits, b, frequency, q, base)\n",
    "                p_fit = get_pdf_fit(p_est)\n",
    "                js = js_divergence(p_est, p_fit)\n",
    "                r = r_divergence(p_est, p_fit, 0.5)\n",
    "                t = t_divergence(p_est, p_fit, 0.5)\n",
    "                feature_vectors[b, n, q] = torch.tensor([js,r,t], device=device)\n",
    "    \n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image, convert to grayscale and crop\n",
    "image = crop_image(cv2.imread(path, cv2.IMREAD_GRAYSCALE), 8)\n",
    "image = torch.tensor(image, dtype=torch.float, device=device)\n",
    "\n",
    "bases = [10, 20, 40]\n",
    "frequencies = [2, 5, 8]\n",
    "quant_matrices = [Q_50, Q_80, Q_90]\n",
    "\n",
    "feature_vectors = get_feature_vector(image, bases, frequencies, quant_matrices)\n",
    "print(\"------- Feature Vectors -------\")\n",
    "print(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conseguir dataset #\n",
    "\n",
    "Una vez conseguido el vector de características, hay que obtener un dataset. En este caso, se va a sacar un archivo csv donde cada fila corresesponde al vector de características de una imagen y el último elemento será la etiqueta de la imagen ('1' si es generada por IA y '0' en el caso contrario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_images(folder_path, n_images, label, bases, frequencies, quant_matrices, filename):\n",
    "    \"\"\"\n",
    "    Process and save feature vectors of a set of images to a CSV file one by one.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): path to the folder containing the images.\n",
    "    - n_images (int): number of images to process.\n",
    "    - label (int): label of the images (1 if AI generated, 0 if not).\n",
    "    - bases (list): list of numerical bases.\n",
    "    - frequencies (list): list of frequency indices.\n",
    "    - quant_matrices (list): list of quantization matrices.\n",
    "    - filename (str): name of the CSV file.\n",
    "    \"\"\"\n",
    "    # Get the image filenames\n",
    "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    n_images = min(n_images, len(image_files))\n",
    "\n",
    "    if n_images == 0:\n",
    "        print(\"No images found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    for i in range(n_images):\n",
    "        image_path = os.path.join(folder_path, image_files[i])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Crop and convert to tensor\n",
    "        image = crop_image(image, BLOCK_SIZE)\n",
    "        image = torch.tensor(image, dtype=torch.float, device=device)\n",
    "\n",
    "        try:\n",
    "            # Extract features\n",
    "            features = get_feature_vector(image, bases, frequencies, quant_matrices)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {image_path}, Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Convert to NumPy and flatten\n",
    "        flattened_features = features.cpu().numpy().flatten()\n",
    "        row = np.append(flattened_features, label)\n",
    "\n",
    "        # Convert to DataFrame and save immediately\n",
    "        df = pd.DataFrame([row])\n",
    "        df.to_csv(filename, mode='a', header=not os.path.exists(filename), index=False)\n",
    "\n",
    "    print(f\"{n_images} images have been processed and saved to {filename}\")\n",
    "\n",
    "def generate_csv_header(divergences, bases, frequencies, qualities, filename):\n",
    "    \"\"\"\n",
    "    Generate and save CSV header based on provided lists.\n",
    "    \"\"\"\n",
    "    \n",
    "    header = []\n",
    "\n",
    "    for b in bases:\n",
    "        for f in frequencies:\n",
    "            for q in qualities:\n",
    "                for d in divergences:\n",
    "                    header.append(f\"{d}_{b}_{f}_{q}\")\n",
    "\n",
    "    header.append(\"label\")\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        df_existing = pd.read_csv(filename)\n",
    "\n",
    "        if list(df_existing.columns) != header:\n",
    "            df_existing.columns = header\n",
    "            df_existing.to_csv(filename, index=False, header=True)  # Sobrescribir con nuevo encabezado\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=header)\n",
    "        df.to_csv(filename, index=False, header=True)\n",
    "        \n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergences_str = [\"js\", \"r\", \"t\"]\n",
    "bases_str = [\"10\", \"20\", \"40\"]\n",
    "frequencies_str = [\"2\", \"5\", \"8\"]\n",
    "qualities_str = [\"50\", \"80\", \"90\"]\n",
    "filename = \"features.csv\"\n",
    "\n",
    "csv_header = generate_csv_header(divergences_str, bases_str, frequencies_str, qualities_str, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_natural = \"dummy-images/natural\"\n",
    "ruta_ia = \"dummy-images/ia\"\n",
    "\n",
    "process_and_save_images(ruta_natural, 10, '0', bases, frequencies, quant_matrices, \"features.csv\")\n",
    "process_and_save_images(ruta_ia, 10, '1', bases, frequencies, quant_matrices, \"features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
